[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- [나동빈님 Github](https://colab.research.google.com/github/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/GAN_for_MNIST_Tutorial.ipynb#scrollTo=CiRb7M3naHyo)  \n",
    "GAN for MNIST Tutorial\n",
    "- [최윤제님 Github](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L42)  \n",
    "pytorch-tutorial/tutorials/03-advanced/generative_adversarial_network/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets    # To load MNIST dataset, import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` save_image\n",
    "- [save_image](https://pytorch.org/vision/stable/generated/torchvision.utils.save_image.html#torchvision.utils.save_image) : Save a given Tensor into an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. System Setting and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cuda configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100    # latent vector\n",
    "image_size = 28*28   # 28 x 28 = 784\n",
    "num_epochs = 200\n",
    "lr = 0.0002\n",
    "mean = [0.5]\n",
    "std = [0.5]\n",
    "# batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Discriminator and Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [nn.LeakyReLU(negative_slope=0.1, inplace=False)](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html)\n",
    "- [(image) LeakyReLU activation function](https://pytorch.org/docs/stable/_images/LeakyReLU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define Discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        # reshape image to one dimension (flattened)\n",
    "        image_input = image.reshape(image.size(0), -1)\n",
    "        output = self.model(image_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define Generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        image_output = self.model(z)\n",
    "        input = image_output.reshape(image_output.size(0), 1, 28, 28)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load data (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` transforms.Normalize() ➡️ right_arrow Standardization\n",
    "- output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "- [Normalization, Standardization, ...](https://realblack0.github.io/2020/03/29/normalization-standardization-regularization.html)\n",
    "\n",
    "`-` Denormalize  \n",
    "- [Denormalize_1](https://github.com/pytorch/vision/issues/848)\n",
    "- [Denormalize_2](https://discuss.pytorch.org/t/issue-with-using-dataparallel-runtimeerror-output-0-of-broadcastbackward-is-a-view-and-its-base-or-another-view-of-its-base-has-been-modified-inplace/84677)\n",
    "- $X' = \\frac{X\\ -\\  \\mu}{\\sigma}$ ➡️ $X = X'\\sigma\\ +\\ \\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std) # Since MNIST is graycale, just using 1 channel\n",
    "])\n",
    "\n",
    "def denormalize(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_dataset = datasets.MNIST(root=\"./MNIST_dir\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(MNIST_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Cuda setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discriminator = discriminator()\n",
    "Generator = generator()\n",
    "\n",
    "Discriminator.cuda()\n",
    "Generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=784, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Discriminator, end=\"\\n\")\n",
    "print(Generator, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "# criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = torch.optim.Adam(Discriminator.parameters(),\n",
    "    lr=lr,\n",
    "    betas=(0.5, 0.999))\n",
    "\n",
    "G_optimizer = torch.optim.Adam(Generator.parameters(),\n",
    "    lr=lr,\n",
    "    betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200]  d_total_loss 0.1982  g_fake_loss 3.6464\n",
      "Epoch [1/200]  d_total_loss 0.5632  g_fake_loss 4.0442\n",
      "Epoch [2/200]  d_total_loss 0.2325  g_fake_loss 3.4393\n",
      "Epoch [3/200]  d_total_loss 0.2285  g_fake_loss 1.3144\n",
      "Epoch [4/200]  d_total_loss 0.7820  g_fake_loss 6.3295\n",
      "Epoch [5/200]  d_total_loss 0.3884  g_fake_loss 1.4747\n",
      "Epoch [6/200]  d_total_loss 0.3206  g_fake_loss 2.3737\n",
      "Epoch [7/200]  d_total_loss 0.3504  g_fake_loss 2.6543\n",
      "Epoch [8/200]  d_total_loss 0.7078  g_fake_loss 6.2611\n",
      "Epoch [9/200]  d_total_loss 0.4590  g_fake_loss 1.5432\n",
      "Epoch [10/200]  d_total_loss 1.2903  g_fake_loss 1.8122\n",
      "Epoch [11/200]  d_total_loss 1.1547  g_fake_loss 8.3247\n",
      "Epoch [12/200]  d_total_loss 0.4427  g_fake_loss 3.7032\n",
      "Epoch [13/200]  d_total_loss 0.3775  g_fake_loss 2.0408\n",
      "Epoch [14/200]  d_total_loss 0.5688  g_fake_loss 1.6185\n",
      "Epoch [15/200]  d_total_loss 0.6020  g_fake_loss 1.3567\n",
      "Epoch [16/200]  d_total_loss 0.5986  g_fake_loss 3.2114\n",
      "Epoch [17/200]  d_total_loss 0.6567  g_fake_loss 2.5583\n",
      "Epoch [18/200]  d_total_loss 0.6319  g_fake_loss 2.3779\n",
      "Epoch [19/200]  d_total_loss 0.6110  g_fake_loss 1.9028\n",
      "Epoch [20/200]  d_total_loss 0.6259  g_fake_loss 1.8508\n",
      "Epoch [21/200]  d_total_loss 0.5631  g_fake_loss 1.7271\n",
      "Epoch [22/200]  d_total_loss 0.5021  g_fake_loss 2.3752\n",
      "Epoch [23/200]  d_total_loss 0.5798  g_fake_loss 2.2521\n",
      "Epoch [24/200]  d_total_loss 0.7869  g_fake_loss 2.7717\n",
      "Epoch [25/200]  d_total_loss 1.0275  g_fake_loss 2.4797\n",
      "Epoch [26/200]  d_total_loss 0.7273  g_fake_loss 1.6263\n",
      "Epoch [27/200]  d_total_loss 0.6469  g_fake_loss 1.8589\n",
      "Epoch [28/200]  d_total_loss 0.7767  g_fake_loss 2.6213\n",
      "Epoch [29/200]  d_total_loss 0.7355  g_fake_loss 1.9832\n",
      "Epoch [30/200]  d_total_loss 0.8009  g_fake_loss 1.5731\n",
      "Epoch [31/200]  d_total_loss 1.1151  g_fake_loss 0.9541\n",
      "Epoch [32/200]  d_total_loss 0.8780  g_fake_loss 2.5381\n",
      "Epoch [33/200]  d_total_loss 0.6967  g_fake_loss 1.4911\n",
      "Epoch [34/200]  d_total_loss 0.7475  g_fake_loss 1.4525\n",
      "Epoch [35/200]  d_total_loss 0.8197  g_fake_loss 1.2742\n",
      "Epoch [36/200]  d_total_loss 0.8167  g_fake_loss 0.9366\n",
      "Epoch [37/200]  d_total_loss 1.6773  g_fake_loss 0.9171\n",
      "Epoch [38/200]  d_total_loss 0.8480  g_fake_loss 2.2224\n",
      "Epoch [39/200]  d_total_loss 0.7592  g_fake_loss 1.6088\n",
      "Epoch [40/200]  d_total_loss 0.7813  g_fake_loss 1.1420\n",
      "Epoch [41/200]  d_total_loss 0.7694  g_fake_loss 1.3037\n",
      "Epoch [42/200]  d_total_loss 0.7702  g_fake_loss 1.6368\n",
      "Epoch [43/200]  d_total_loss 0.7490  g_fake_loss 1.8875\n",
      "Epoch [44/200]  d_total_loss 1.3645  g_fake_loss 3.1067\n",
      "Epoch [45/200]  d_total_loss 0.9166  g_fake_loss 2.1351\n",
      "Epoch [46/200]  d_total_loss 0.6829  g_fake_loss 1.7661\n",
      "Epoch [47/200]  d_total_loss 0.7755  g_fake_loss 1.2279\n",
      "Epoch [48/200]  d_total_loss 0.7158  g_fake_loss 1.5262\n",
      "Epoch [49/200]  d_total_loss 0.8450  g_fake_loss 0.9775\n",
      "Epoch [50/200]  d_total_loss 0.5651  g_fake_loss 1.9606\n",
      "Epoch [51/200]  d_total_loss 0.7878  g_fake_loss 2.4610\n",
      "Epoch [52/200]  d_total_loss 0.7235  g_fake_loss 1.3103\n",
      "Epoch [53/200]  d_total_loss 0.6662  g_fake_loss 1.9166\n",
      "Epoch [54/200]  d_total_loss 0.7154  g_fake_loss 2.6813\n",
      "Epoch [55/200]  d_total_loss 0.6988  g_fake_loss 1.4358\n",
      "Epoch [56/200]  d_total_loss 0.8139  g_fake_loss 1.6352\n",
      "Epoch [57/200]  d_total_loss 0.5993  g_fake_loss 2.2511\n",
      "Epoch [58/200]  d_total_loss 0.7123  g_fake_loss 1.6291\n",
      "Epoch [59/200]  d_total_loss 0.7179  g_fake_loss 1.7214\n",
      "Epoch [60/200]  d_total_loss 0.7475  g_fake_loss 2.7522\n",
      "Epoch [61/200]  d_total_loss 0.7790  g_fake_loss 1.5743\n",
      "Epoch [62/200]  d_total_loss 0.9342  g_fake_loss 2.8523\n",
      "Epoch [63/200]  d_total_loss 0.9184  g_fake_loss 0.9755\n",
      "Epoch [64/200]  d_total_loss 0.7560  g_fake_loss 1.7974\n",
      "Epoch [65/200]  d_total_loss 0.6816  g_fake_loss 1.6765\n",
      "Epoch [66/200]  d_total_loss 0.7193  g_fake_loss 1.6864\n",
      "Epoch [67/200]  d_total_loss 0.9034  g_fake_loss 2.8366\n",
      "Epoch [68/200]  d_total_loss 0.7012  g_fake_loss 2.0678\n",
      "Epoch [69/200]  d_total_loss 0.7822  g_fake_loss 1.2890\n",
      "Epoch [70/200]  d_total_loss 0.7182  g_fake_loss 2.1690\n",
      "Epoch [71/200]  d_total_loss 0.6621  g_fake_loss 1.8032\n",
      "Epoch [72/200]  d_total_loss 0.6934  g_fake_loss 2.2556\n",
      "Epoch [73/200]  d_total_loss 0.6888  g_fake_loss 2.0097\n",
      "Epoch [74/200]  d_total_loss 0.7762  g_fake_loss 1.1421\n",
      "Epoch [75/200]  d_total_loss 0.7105  g_fake_loss 2.1012\n",
      "Epoch [76/200]  d_total_loss 0.7367  g_fake_loss 2.1721\n",
      "Epoch [77/200]  d_total_loss 0.8572  g_fake_loss 0.8324\n",
      "Epoch [78/200]  d_total_loss 0.6834  g_fake_loss 2.6085\n",
      "Epoch [79/200]  d_total_loss 0.8849  g_fake_loss 0.9758\n",
      "Epoch [80/200]  d_total_loss 0.6917  g_fake_loss 1.5924\n",
      "Epoch [81/200]  d_total_loss 0.6488  g_fake_loss 2.4961\n",
      "Epoch [82/200]  d_total_loss 0.6728  g_fake_loss 1.9817\n",
      "Epoch [83/200]  d_total_loss 0.6695  g_fake_loss 2.0205\n",
      "Epoch [84/200]  d_total_loss 0.6148  g_fake_loss 1.6975\n",
      "Epoch [85/200]  d_total_loss 0.5969  g_fake_loss 2.0397\n",
      "Epoch [86/200]  d_total_loss 0.6444  g_fake_loss 2.0297\n",
      "Epoch [87/200]  d_total_loss 0.6679  g_fake_loss 2.6489\n",
      "Epoch [88/200]  d_total_loss 0.6151  g_fake_loss 1.5502\n",
      "Epoch [89/200]  d_total_loss 0.6551  g_fake_loss 1.8792\n",
      "Epoch [90/200]  d_total_loss 0.7081  g_fake_loss 2.6492\n",
      "Epoch [91/200]  d_total_loss 0.6372  g_fake_loss 1.6405\n",
      "Epoch [92/200]  d_total_loss 0.6467  g_fake_loss 2.0269\n",
      "Epoch [93/200]  d_total_loss 0.6145  g_fake_loss 2.3049\n",
      "Epoch [94/200]  d_total_loss 0.7850  g_fake_loss 1.5406\n",
      "Epoch [95/200]  d_total_loss 0.7450  g_fake_loss 1.4440\n",
      "Epoch [96/200]  d_total_loss 0.6068  g_fake_loss 2.3025\n",
      "Epoch [97/200]  d_total_loss 0.8050  g_fake_loss 1.2654\n",
      "Epoch [98/200]  d_total_loss 0.6597  g_fake_loss 2.0197\n",
      "Epoch [99/200]  d_total_loss 0.7016  g_fake_loss 2.6921\n",
      "Epoch [100/200]  d_total_loss 0.6474  g_fake_loss 2.6318\n",
      "Epoch [101/200]  d_total_loss 0.7150  g_fake_loss 2.0150\n",
      "Epoch [102/200]  d_total_loss 0.7147  g_fake_loss 2.5400\n",
      "Epoch [103/200]  d_total_loss 0.6883  g_fake_loss 1.8400\n",
      "Epoch [104/200]  d_total_loss 0.6533  g_fake_loss 1.8915\n",
      "Epoch [105/200]  d_total_loss 0.6783  g_fake_loss 1.8367\n",
      "Epoch [106/200]  d_total_loss 0.6068  g_fake_loss 1.6127\n",
      "Epoch [107/200]  d_total_loss 0.6024  g_fake_loss 1.6091\n",
      "Epoch [108/200]  d_total_loss 0.7360  g_fake_loss 3.5056\n",
      "Epoch [109/200]  d_total_loss 0.5761  g_fake_loss 2.1849\n",
      "Epoch [110/200]  d_total_loss 0.6604  g_fake_loss 1.9053\n",
      "Epoch [111/200]  d_total_loss 0.7108  g_fake_loss 2.4620\n",
      "Epoch [112/200]  d_total_loss 0.5434  g_fake_loss 2.2988\n",
      "Epoch [113/200]  d_total_loss 0.6387  g_fake_loss 1.8531\n",
      "Epoch [114/200]  d_total_loss 0.7456  g_fake_loss 1.8285\n",
      "Epoch [115/200]  d_total_loss 0.6047  g_fake_loss 2.3387\n",
      "Epoch [116/200]  d_total_loss 0.9663  g_fake_loss 1.3833\n",
      "Epoch [117/200]  d_total_loss 0.6850  g_fake_loss 1.5863\n",
      "Epoch [118/200]  d_total_loss 0.6851  g_fake_loss 2.1931\n",
      "Epoch [119/200]  d_total_loss 0.5856  g_fake_loss 1.7266\n",
      "Epoch [120/200]  d_total_loss 0.5721  g_fake_loss 2.3992\n",
      "Epoch [121/200]  d_total_loss 0.6017  g_fake_loss 2.1677\n",
      "Epoch [122/200]  d_total_loss 0.6073  g_fake_loss 2.3345\n",
      "Epoch [123/200]  d_total_loss 0.5263  g_fake_loss 2.4989\n",
      "Epoch [124/200]  d_total_loss 0.6205  g_fake_loss 2.0651\n",
      "Epoch [125/200]  d_total_loss 0.6299  g_fake_loss 2.0607\n",
      "Epoch [126/200]  d_total_loss 0.6616  g_fake_loss 1.9202\n",
      "Epoch [127/200]  d_total_loss 0.7040  g_fake_loss 2.3420\n",
      "Epoch [128/200]  d_total_loss 0.5933  g_fake_loss 2.0336\n",
      "Epoch [129/200]  d_total_loss 0.6962  g_fake_loss 1.8239\n",
      "Epoch [130/200]  d_total_loss 0.6897  g_fake_loss 3.1514\n",
      "Epoch [131/200]  d_total_loss 0.6749  g_fake_loss 1.5216\n",
      "Epoch [132/200]  d_total_loss 0.6626  g_fake_loss 1.8018\n",
      "Epoch [133/200]  d_total_loss 0.6929  g_fake_loss 1.9053\n",
      "Epoch [134/200]  d_total_loss 0.6143  g_fake_loss 2.2504\n",
      "Epoch [135/200]  d_total_loss 0.7047  g_fake_loss 2.0832\n",
      "Epoch [136/200]  d_total_loss 0.6775  g_fake_loss 2.3875\n",
      "Epoch [137/200]  d_total_loss 0.6071  g_fake_loss 2.2575\n",
      "Epoch [138/200]  d_total_loss 0.7050  g_fake_loss 1.7102\n",
      "Epoch [139/200]  d_total_loss 0.6429  g_fake_loss 1.6140\n",
      "Epoch [140/200]  d_total_loss 0.6160  g_fake_loss 1.9475\n",
      "Epoch [141/200]  d_total_loss 0.6904  g_fake_loss 1.7859\n",
      "Epoch [142/200]  d_total_loss 0.6044  g_fake_loss 2.2893\n",
      "Epoch [143/200]  d_total_loss 0.6016  g_fake_loss 2.2753\n",
      "Epoch [144/200]  d_total_loss 0.6437  g_fake_loss 1.9717\n",
      "Epoch [145/200]  d_total_loss 0.4045  g_fake_loss 2.5739\n",
      "Epoch [146/200]  d_total_loss 0.6040  g_fake_loss 1.9887\n",
      "Epoch [147/200]  d_total_loss 0.4807  g_fake_loss 2.9580\n",
      "Epoch [148/200]  d_total_loss 0.6142  g_fake_loss 1.9158\n",
      "Epoch [149/200]  d_total_loss 0.6270  g_fake_loss 2.2207\n",
      "Epoch [150/200]  d_total_loss 0.6144  g_fake_loss 2.5870\n",
      "Epoch [151/200]  d_total_loss 0.5620  g_fake_loss 1.8921\n",
      "Epoch [152/200]  d_total_loss 0.6132  g_fake_loss 2.5865\n",
      "Epoch [153/200]  d_total_loss 0.6973  g_fake_loss 1.5272\n",
      "Epoch [154/200]  d_total_loss 0.5164  g_fake_loss 2.4498\n",
      "Epoch [155/200]  d_total_loss 0.5695  g_fake_loss 2.6232\n",
      "Epoch [156/200]  d_total_loss 0.5208  g_fake_loss 2.5359\n",
      "Epoch [157/200]  d_total_loss 0.5889  g_fake_loss 1.9903\n",
      "Epoch [158/200]  d_total_loss 0.5844  g_fake_loss 2.1193\n",
      "Epoch [159/200]  d_total_loss 0.4814  g_fake_loss 2.7699\n",
      "Epoch [160/200]  d_total_loss 0.6126  g_fake_loss 1.8688\n",
      "Epoch [161/200]  d_total_loss 0.7505  g_fake_loss 2.2666\n",
      "Epoch [162/200]  d_total_loss 0.6389  g_fake_loss 1.6929\n",
      "Epoch [163/200]  d_total_loss 0.6637  g_fake_loss 3.7651\n",
      "Epoch [164/200]  d_total_loss 0.6967  g_fake_loss 1.6645\n",
      "Epoch [165/200]  d_total_loss 0.6500  g_fake_loss 2.2168\n",
      "Epoch [166/200]  d_total_loss 0.5514  g_fake_loss 2.2114\n",
      "Epoch [167/200]  d_total_loss 0.5442  g_fake_loss 2.6182\n",
      "Epoch [168/200]  d_total_loss 0.5597  g_fake_loss 2.1672\n",
      "Epoch [169/200]  d_total_loss 0.5525  g_fake_loss 2.1664\n",
      "Epoch [170/200]  d_total_loss 0.5203  g_fake_loss 3.2767\n",
      "Epoch [171/200]  d_total_loss 0.6628  g_fake_loss 2.3628\n",
      "Epoch [172/200]  d_total_loss 0.4960  g_fake_loss 3.3958\n",
      "Epoch [173/200]  d_total_loss 0.4572  g_fake_loss 2.6782\n",
      "Epoch [174/200]  d_total_loss 0.5695  g_fake_loss 1.9442\n",
      "Epoch [175/200]  d_total_loss 0.4663  g_fake_loss 2.6792\n",
      "Epoch [176/200]  d_total_loss 0.6140  g_fake_loss 2.1277\n",
      "Epoch [177/200]  d_total_loss 0.5577  g_fake_loss 2.7650\n",
      "Epoch [178/200]  d_total_loss 0.5412  g_fake_loss 2.2505\n",
      "Epoch [179/200]  d_total_loss 0.4764  g_fake_loss 2.6662\n",
      "Epoch [180/200]  d_total_loss 0.5606  g_fake_loss 2.4415\n",
      "Epoch [181/200]  d_total_loss 0.5234  g_fake_loss 2.2640\n",
      "Epoch [182/200]  d_total_loss 0.5424  g_fake_loss 3.2490\n",
      "Epoch [183/200]  d_total_loss 0.5430  g_fake_loss 2.3135\n",
      "Epoch [184/200]  d_total_loss 0.4815  g_fake_loss 2.5474\n",
      "Epoch [185/200]  d_total_loss 0.5532  g_fake_loss 2.1053\n",
      "Epoch [186/200]  d_total_loss 0.4287  g_fake_loss 2.9487\n",
      "Epoch [187/200]  d_total_loss 0.5004  g_fake_loss 2.2487\n",
      "Epoch [188/200]  d_total_loss 0.5201  g_fake_loss 2.1448\n",
      "Epoch [189/200]  d_total_loss 0.5216  g_fake_loss 1.9860\n",
      "Epoch [190/200]  d_total_loss 0.5572  g_fake_loss 2.6839\n",
      "Epoch [191/200]  d_total_loss 0.5060  g_fake_loss 2.1378\n",
      "Epoch [192/200]  d_total_loss 0.5311  g_fake_loss 2.2781\n",
      "Epoch [193/200]  d_total_loss 0.5614  g_fake_loss 2.3797\n",
      "Epoch [194/200]  d_total_loss 0.4484  g_fake_loss 2.8587\n",
      "Epoch [195/200]  d_total_loss 0.5568  g_fake_loss 2.8460\n",
      "Epoch [196/200]  d_total_loss 0.3043  g_fake_loss 2.9490\n",
      "Epoch [197/200]  d_total_loss 0.6947  g_fake_loss 2.6417\n",
      "Epoch [198/200]  d_total_loss 0.4332  g_fake_loss 2.5072\n",
      "Epoch [199/200]  d_total_loss 0.5423  g_fake_loss 1.9557\n"
     ]
    }
   ],
   "source": [
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        real_images = images.to(device)\n",
    "\n",
    "        # Create real labels and fake labels\n",
    "        real_labels = torch.cuda.FloatTensor(images.size(0), 1).fill_(1.0)\n",
    "        # real_labels = torch.ones(images.size(0), 1)\n",
    "        fake_labels = torch.cuda.FloatTensor(images.size(0), 1).fill_(0.0)\n",
    "        # fake_labels = torch.zeros(images.size(0), 1)\n",
    "\n",
    "\n",
    "        ################# Train the Discriminator #################\n",
    "        \n",
    "        ## Real loss of Discriminator ##\n",
    "        d_real_output = Discriminator(real_images)\n",
    "        d_real_loss = criterion(d_real_output, real_labels)\n",
    "\n",
    "        ## Fake loss of Discriminator ##\n",
    "        z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
    "        g_fake_output = Generator(z)\n",
    "        d_g_fake_output = Discriminator(g_fake_output)\n",
    "        d_fake_loss = criterion(d_g_fake_output, fake_labels)\n",
    "\n",
    "        ## Total loss of Discriminator ##\n",
    "        d_total_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "        ## Update Discriminator for backpropagation and Optimizer ##\n",
    "        D_optimizer.zero_grad()\n",
    "        d_total_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "\n",
    "        ################# Train the Generator #################\n",
    "        g_fake_output = Generator(z)\n",
    "        g_fake_loss = criterion(Discriminator(g_fake_output), real_labels)\n",
    "        G_optimizer.zero_grad()\n",
    "        g_fake_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "    # Print log per one epoch\n",
    "    print(\"Epoch [{}/{}]  d_total_loss {:.4f}  g_fake_loss {:.4f}\"\n",
    "        .format(epoch, num_epochs, d_total_loss.item(), g_fake_loss.item()))\n",
    "\n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        real_images = real_images.reshape(real_images.size(0), 1, 28, 28)\n",
    "        save_image(denormalize(real_images).data[:100], \"real-image_{}.png\".format(epoch+1), nrow=10)\n",
    "\n",
    "    # Save fake images\n",
    "    fake_images = g_fake_output.reshape(g_fake_output.size(0), 1, 28, 28)\n",
    "    save_image(denormalize(fake_images).data[:100], \"fake-image_{}.png\".format(epoch+1), nrow=10, normalize=False)\n",
    "\n",
    "# Save the model checkpoints\n",
    "torch.save(Discriminator.state_dict(), \"Discriminator.ckpt\")\n",
    "torch.save(Generator.state_dict(), \"Generator.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(denormalize(fake_images).data[:100], \"fake-image_{}.png\".format(201), nrow=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_discrim = discriminator().to(device)\n",
    "model_discrim.load_state_dict(torch.load(\"Discriminator.ckpt\"))\n",
    "\n",
    "model_gener = generator().to(device)\n",
    "model_gener.load_state_dict(torch.load(\"Generator.ckpt\"))\n",
    "\n",
    "model_discrim.eval()\n",
    "model_gener.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        real_images = images.to(device)\n",
    "\n",
    "        # Create real labels and fake labels\n",
    "        real_labels = torch.cuda.FloatTensor(images.size(0), 1).fill_(1.0)\n",
    "        # real_labels = torch.ones(images.size(0), 1)\n",
    "        fake_labels = torch.cuda.FloatTensor(images.size(0), 1).fill_(0.0)\n",
    "        # fake_labels = torch.zeros(images.size(0), 1)\n",
    "\n",
    "\n",
    "        ################# Train the Discriminator #################\n",
    "        \n",
    "        ## Real loss of Discriminator ##\n",
    "        d_real_output = Discriminator(real_images)\n",
    "        d_real_loss = criterion(d_real_output, real_labels)\n",
    "\n",
    "        ## Fake loss of Discriminator ##\n",
    "        z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
    "        g_fake_output = Generator(z)\n",
    "        d_g_fake_output = Discriminator(g_fake_output)\n",
    "        d_fake_loss = criterion(d_g_fake_output, fake_labels)\n",
    "\n",
    "        ## Total loss of Discriminator ##\n",
    "        d_total_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "        ## Update Discriminator for backpropagation and Optimizer ##\n",
    "        D_optimizer.zero_grad()\n",
    "        d_total_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "\n",
    "        ################# Train the Generator #################\n",
    "        g_fake_output = Generator(z)\n",
    "        g_fake_loss = criterion(Discriminator(g_fake_output), real_labels)\n",
    "        G_optimizer.zero_grad()\n",
    "        g_fake_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "    # Print log per one epoch\n",
    "    print(\"Epoch [{}/{}]  d_total_loss {:.4f}  g_fake_loss {:.4f}\"\n",
    "        .format(epoch, num_epochs, d_total_loss.item(), g_fake_loss.item()))\n",
    "\n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        real_images = real_images.reshape(real_images.size(0), 1, 28, 28)\n",
    "        save_image(denormalize(real_images).data[:25], \"real-image_{}.png\".format(epoch+1), nrow=5)\n",
    "\n",
    "    # Save fake images\n",
    "    fake_images = g_fake_output.reshape(g_fake_output.size(0), 1, 28, 28)\n",
    "    save_image(denormalize(fake_images).data[:25], \"fake-image_{}.png\".format(epoch+1), nrow=5, normalize=False)\n",
    "\n",
    "# Save the model checkpoints\n",
    "torch.save(Discriminator.state_dict(), \"Discriminator.ckpt\")\n",
    "torch.save(Generator.state_dict(), \"Generator.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
    "g_fake_output = model_gener(z)\n",
    "fake_images = g_fake_output.reshape(g_fake_output.size(0), 1, 28, 28)\n",
    "save_image(denormalize(fake_images).data[:100], \"fake-image_generated.png\", nrow=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = plt.imread('fake-image_generated.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1896f1f9beccb884a76613e7e26e3d0c6c1a124ef4e9961146273961a5e6b65c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
